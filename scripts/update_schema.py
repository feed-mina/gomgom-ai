#!/usr/bin/env python3
"""
ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Redis ìºì‹œ ë°ì´í„°ë¥¼ PostgreSQLì— ì €ì¥í•˜ê¸° ìœ„í•œ cache_data í…Œì´ë¸” ìƒì„±
"""

import psycopg2
import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from app.core.config import settings

def create_cache_data_table():
    """cache_data í…Œì´ë¸” ìƒì„±"""
    try:
        # PostgreSQL ì—°ê²°
        conn = psycopg2.connect(
            dbname=settings.POSTGRES_DB,
            user=settings.POSTGRES_USER,
            password=settings.POSTGRES_PASSWORD,
            host=settings.POSTGRES_SERVER,
            port=settings.POSTGRES_PORT,
            connect_timeout=10
        )
        
        with conn.cursor() as cursor:
            # cache_data í…Œì´ë¸” ìƒì„±
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS cache_data (
                    id SERIAL PRIMARY KEY,
                    cache_key VARCHAR(255) UNIQUE NOT NULL,
                    data_type VARCHAR(100) NOT NULL,
                    data JSONB NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_cache_data_key ON cache_data(cache_key)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_cache_data_type ON cache_data(data_type)
            """)
            
            # updated_at íŠ¸ë¦¬ê±° í•¨ìˆ˜ê°€ ì—†ìœ¼ë©´ ìƒì„±
            cursor.execute("""
                CREATE OR REPLACE FUNCTION update_updated_at_column()
                RETURNS TRIGGER AS $$
                BEGIN
                    NEW.updated_at = CURRENT_TIMESTAMP;
                    RETURN NEW;
                END;
                $$ language 'plpgsql'
            """)
            
            # íŠ¸ë¦¬ê±° ìƒì„±
            cursor.execute("""
                DROP TRIGGER IF EXISTS update_cache_data_updated_at ON cache_data
            """)
            
            cursor.execute("""
                CREATE TRIGGER update_cache_data_updated_at
                    BEFORE UPDATE ON cache_data
                    FOR EACH ROW
                    EXECUTE FUNCTION update_updated_at_column()
            """)
            
            conn.commit()
            print("âœ… cache_data í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            
            # í…Œì´ë¸” ì •ë³´ í™•ì¸
            cursor.execute("""
                SELECT column_name, data_type, is_nullable 
                FROM information_schema.columns 
                WHERE table_name = 'cache_data'
                ORDER BY ordinal_position
            """)
            
            columns = cursor.fetchall()
            print("\nğŸ“‹ cache_data í…Œì´ë¸” êµ¬ì¡°:")
            for col in columns:
                # Print(f"  - {col[0]}: {col[1]} ({'NULL' if col[2] == 'YES' else 'NOT NULL'})")
            
            return True
            
    except Exception as e:
        # Print(f"âŒ cache_data í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
        if conn:
            conn.rollback()
        return False
    finally:
        if conn:
            conn.close()

def check_existing_data():
    """ê¸°ì¡´ ìºì‹œ ë°ì´í„° í™•ì¸"""
    try:
        conn = psycopg2.connect(
            dbname=settings.POSTGRES_DB,
            user=settings.POSTGRES_USER,
            password=settings.POSTGRES_PASSWORD,
            host=settings.POSTGRES_SERVER,
            port=settings.POSTGRES_PORT,
            connect_timeout=10
        )
        
        with conn.cursor() as cursor:
            cursor.execute("SELECT COUNT(*) FROM cache_data")
            count = cursor.fetchone()[0]
            # Print(f"\nğŸ“Š í˜„ì¬ cache_data í…Œì´ë¸”ì— {count}ê°œì˜ ë ˆì½”ë“œê°€ ìˆìŠµë‹ˆë‹¤.")
            
            if count > 0:
                cursor.execute("""
                    SELECT data_type, COUNT(*) 
                    FROM cache_data 
                    GROUP BY data_type 
                    ORDER BY COUNT(*) DESC
                """)
                
                types = cursor.fetchall()
                print("\nğŸ“ˆ ë°ì´í„° íƒ€ì…ë³„ ë¶„í¬:")
                for data_type, count in types:
                    # Print(f"  - {data_type}: {count}ê°œ")
            
            return True
            
    except Exception as e:
        # Print(f"âŒ ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
        return False
    finally:
        if conn:
            conn.close()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # 1. cache_data í…Œì´ë¸” ìƒì„±
    if create_cache_data_table():
        print("\nâœ… ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # 2. ê¸°ì¡´ ë°ì´í„° í™•ì¸
        check_existing_data()
        
        print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ’¡ ì´ì œ Redis ìºì‹œ ë°ì´í„°ê°€ PostgreSQLì—ë„ ìë™ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.")
        print("   - ë¹ ë¥¸ ì¡°íšŒ: Redisì—ì„œ ë¨¼ì € ì¡°íšŒ")
        print("   - ì˜êµ¬ ì €ì¥: PostgreSQLì— ë°±ì—… ì €ì¥")
        print("   - ë³µêµ¬ ê¸°ëŠ¥: Redis ì¥ì•  ì‹œ PostgreSQLì—ì„œ ë³µêµ¬")
    else:
        print("\nâŒ ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
        sys.exit(1)

if __name__ == "__main__":
    main() 