#!/usr/bin/env python3
"""
Performance Monitoring Script

This script monitors application performance by:
1. Database query performance
2. API response times
3. Cache hit rates
4. System resource usage
"""

import sys
import os
import time
import psutil
import requests
import psycopg2
from psycopg2.extras import RealDictCursor
import logging
from datetime import datetime, timedelta
import json

# Add project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.config import settings

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('performance_monitor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PerformanceMonitor:
    def __init__(self):
        self.api_url = settings.BACKEND_CORS_ORIGINS[0] if settings.BACKEND_CORS_ORIGINS else "http://localhost:8000"
        self.db_config = {
            'dbname': settings.POSTGRES_DB,
            'user': settings.POSTGRES_USER,
            'password': settings.POSTGRES_PASSWORD,
            'host': settings.POSTGRES_SERVER,
            'port': settings.POSTGRES_PORT
        }
        self.metrics = {
            'database': {},
            'api': {},
            'system': {},
            'cache': {}
        }

    def get_db_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        return psycopg2.connect(**self.db_config)

    def monitor_database_performance(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        # # logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        try:
            conn = self.get_db_connection()
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            # í™œì„± ì—°ê²° ìˆ˜ í™•ì¸
            cursor.execute("SELECT count(*) as active_connections FROM pg_stat_activity WHERE state = 'active';")
            active_connections = cursor.fetchone()['active_connections']
            
            # ëŠë¦° ì¿¼ë¦¬ í™•ì¸
            cursor.execute("""
                SELECT 
                    query,
                    calls,
                    total_time,
                    mean_time,
                    rows,
                    shared_blks_hit,
                    shared_blks_read
                FROM pg_stat_statements
                ORDER BY mean_time DESC
                LIMIT 5;
            """)
            
            slow_queries = cursor.fetchall()
            
            # í…Œì´ë¸” í¬ê¸° í™•ì¸
            cursor.execute("""
                SELECT 
                    schemaname,
                    tablename,
                    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
                FROM pg_tables
                WHERE schemaname = 'public'
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
            """)
            
            table_sizes = cursor.fetchall()
            
            # ì¸ë±ìŠ¤ ì‚¬ìš©ë¥  í™•ì¸
            cursor.execute("""
                SELECT 
                    indexname,
                    idx_scan,
                    idx_tup_read,
                    idx_tup_fetch
                FROM pg_stat_user_indexes
                ORDER BY idx_scan DESC
                LIMIT 10;
            """)
            
            index_usage = cursor.fetchall()
            
            self.metrics['database'] = {
                'active_connections': active_connections,
                'slow_queries': [dict(q) for q in slow_queries],
                'table_sizes': [dict(t) for t in table_sizes],
                'index_usage': [dict(i) for i in index_usage],
                'timestamp': datetime.now().isoformat()
            }
            
            cursor.close()
            conn.close()
            
            # # logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ - í™œì„± ì—°ê²°: {active_connections}")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")

    def monitor_api_performance(self):
        """API ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        # # logger.info("API ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        api_endpoints = [
            '/api/v1/recipes/',
            '/api/v1/ingredients/',
            '/api/v1/locations/',
            '/api/v1/recommendations/',
            '/health'
        ]
        
        api_metrics = {}
        
        for endpoint in api_endpoints:
            try:
                start_time = time.time()
                response = requests.get(f"{self.api_url}{endpoint}", timeout=10)
                response_time = (time.time() - start_time) * 1000  # ms
                
                api_metrics[endpoint] = {
                    'status_code': response.status_code,
                    'response_time_ms': round(response_time, 2),
                    'content_length': len(response.content),
                    'timestamp': datetime.now().isoformat()
                }
                
                # # logger.info(f"API {endpoint}: {response_time:.2f}ms")
                
            except Exception as e:
                logger.error(f"API ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨ {endpoint}: {e}")
                api_metrics[endpoint] = {
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
        
        self.metrics['api'] = api_metrics

    def monitor_system_resources(self):
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
        # # logger.info("ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        try:
            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            memory = psutil.virtual_memory()
            
            # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
            disk = psutil.disk_usage('/')
            
            # ë„¤íŠ¸ì›Œí¬ I/O
            network = psutil.net_io_counters()
            
            self.metrics['system'] = {
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'memory_available_gb': round(memory.available / (1024**3), 2),
                'disk_percent': disk.percent,
                'disk_free_gb': round(disk.free / (1024**3), 2),
                'network_bytes_sent': network.bytes_sent,
                'network_bytes_recv': network.bytes_recv,
                'timestamp': datetime.now().isoformat()
            }
            
            # # logger.info(f"ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ - CPU: {cpu_percent}%, ë©”ëª¨ë¦¬: {memory.percent}%")
            
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")

    def monitor_cache_performance(self):
        """ìºì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        # # logger.info("ìºì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        try:
            import redis
            
            redis_client = redis.Redis(
                host=os.getenv("REDIS_HOST", "localhost"),
                port=int(os.getenv("REDIS_PORT", 6379)),
                db=0,
                decode_responses=True
            )
            
            # Redis ì •ë³´ ì¡°íšŒ
            info = redis_client.info()
            
            # ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°
            keyspace_hits = info.get('keyspace_hits', 0)
            keyspace_misses = info.get('keyspace_misses', 0)
            total_requests = keyspace_hits + keyspace_misses
            hit_rate = (keyspace_hits / total_requests * 100) if total_requests > 0 else 0
            
            self.metrics['cache'] = {
                'connected_clients': info.get('connected_clients', 0),
                'used_memory_human': info.get('used_memory_human', '0B'),
                'total_commands_processed': info.get('total_commands_processed', 0),
                'keyspace_hits': keyspace_hits,
                'keyspace_misses': keyspace_misses,
                'hit_rate_percent': round(hit_rate, 2),
                'timestamp': datetime.now().isoformat()
            }
            
            # # logger.info(f"ìºì‹œ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ - íˆíŠ¸ìœ¨: {hit_rate:.2f}%")
            
        except Exception as e:
            logger.error(f"ìºì‹œ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")
            self.metrics['cache'] = {
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }

    def generate_performance_report(self):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        # # logger.info("ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'database_connections': self.metrics['database'].get('active_connections', 0),
                'slowest_api_endpoint': self._get_slowest_api_endpoint(),
                'system_cpu_percent': self.metrics['system'].get('cpu_percent', 0),
                'cache_hit_rate': self.metrics['cache'].get('hit_rate_percent', 0)
            },
            'details': self.metrics,
            'recommendations': self._generate_recommendations()
        }
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_file = f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # # logger.info(f"ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_file}")
        
        # ì½˜ì†”ì— ìš”ì•½ ì¶œë ¥
        self._print_summary(report)
        
        return report

    def _get_slowest_api_endpoint(self):
        """ê°€ì¥ ëŠë¦° API ì—”ë“œí¬ì¸íŠ¸ ì°¾ê¸°"""
        slowest = None
        slowest_time = 0
        
        for endpoint, metrics in self.metrics['api'].items():
            if 'response_time_ms' in metrics and metrics['response_time_ms'] > slowest_time:
                slowest = endpoint
                slowest_time = metrics['response_time_ms']
        
        return {'endpoint': slowest, 'response_time_ms': slowest_time} if slowest else None

    def _generate_recommendations(self):
        """ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê¶Œì¥ì‚¬í•­
        db_metrics = self.metrics['database']
        if db_metrics.get('active_connections', 0) > 50:
            recommendations.append("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ ì—°ê²°ì„ ìµœì í™”í•˜ì„¸ìš”.")
        
        slow_queries = db_metrics.get('slow_queries', [])
        if slow_queries:
            recommendations.append(f"{len(slow_queries)}ê°œì˜ ëŠë¦° ì¿¼ë¦¬ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ ì¶”ê°€ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # API ê¶Œì¥ì‚¬í•­
        api_metrics = self.metrics['api']
        for endpoint, metrics in api_metrics.items():
            if 'response_time_ms' in metrics and metrics['response_time_ms'] > 1000:
                recommendations.append(f"API {endpoint}ì˜ ì‘ë‹µ ì‹œê°„ì´ 1ì´ˆë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì‹œìŠ¤í…œ ê¶Œì¥ì‚¬í•­
        system_metrics = self.metrics['system']
        if system_metrics.get('cpu_percent', 0) > 80:
            recommendations.append("CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ì„œë²„ ë¦¬ì†ŒìŠ¤ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ ë¶€í•˜ë¥¼ ë¶„ì‚°í•˜ì„¸ìš”.")
        
        if system_metrics.get('memory_percent', 0) > 90:
            recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë©”ëª¨ë¦¬ë¥¼ ëŠ˜ë¦¬ì„¸ìš”.")
        
        # ìºì‹œ ê¶Œì¥ì‚¬í•­
        cache_metrics = self.metrics['cache']
        if cache_metrics.get('hit_rate_percent', 0) < 50:
            recommendations.append("ìºì‹œ íˆíŠ¸ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ìºì‹œ ì „ëµì„ ì¬ê²€í† í•˜ì„¸ìš”.")
        
        return recommendations

    def _print_summary(self, report):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ ìš”ì•½")
        print("="*60)
        
        summary = report['summary']
        # Print(f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°: {summary['database_connections']}ê°œ")
        
        slowest_api = summary['slowest_api_endpoint']
        if slowest_api:
            # Print(f"ğŸŒ ê°€ì¥ ëŠë¦° API: {slowest_api['endpoint']} ({slowest_api['response_time_ms']:.2f}ms)")
        
        # Print(f"ğŸ’» CPU ì‚¬ìš©ë¥ : {summary['system_cpu_percent']:.1f}%")
        # Print(f"ğŸ¯ ìºì‹œ íˆíŠ¸ìœ¨: {summary['cache_hit_rate']:.1f}%")
        
        recommendations = report['recommendations']
        if recommendations:
            # Print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­ ({len(recommendations)}ê°œ):")
            for i, rec in enumerate(recommendations, 1):
                # Print(f"  {i}. {rec}")
        
        print("="*60)

    def run_monitoring(self):
        """ì „ì²´ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        # # logger.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        try:
            # ê° ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
            self.monitor_database_performance()
            self.monitor_api_performance()
            self.monitor_system_resources()
            self.monitor_cache_performance()
            
            # ë¦¬í¬íŠ¸ ìƒì„±
            report = self.generate_performance_report()
            
            # # logger.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ")
            return report
            
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    monitor = PerformanceMonitor()
    report = monitor.run_monitoring()
    
    if report:
        print("âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)

if __name__ == "__main__":
    main() 